{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "### EP3 MAC0417 / MAC5768 ##################################################\n",
    "#  AO PREENCHER ESSE CABEÇALHO COM O MEU NOME E O MEU NÚMERO USP,              #\n",
    "#  DECLARO QUE SOU O ÚNICO AUTOR E RESPONSÁVEL PELAS RESPOSTAS NESTA LISTA.    #\n",
    "#  TODAS AS PARTES FORAM DESENVOLVIDAS E IMPLEMENTADAS POR MIM, SEGUINDO AS    #\n",
    "#  INSTRUÇÕES E QUE PORTANTO, NÃO CONSTITUEM DESONESTIDADE ACADÊMICA OU PLÁGIO.#\n",
    "#                                                                              #\n",
    "#  DECLARO TAMBÉM QUE SOU RESPONSÁVEL POR TODAS AS CÓPIAS                      #\n",
    "#  DESSE PROGRAMA E QUE EU NÃO DISTRIBUI OU FACILITEI A                        #\n",
    "#  SUA DISTRIBUIÇÃO. ESTOU CIENTE QUE OS CASOS DE PLÁGIO E                     #\n",
    "#  DESONESTIDADE ACADÊMICA SERÃO TRATADOS SEGUNDO OS CRITÉRIOS                 #\n",
    "#  DEFINIDOS NO CÓDIGO DE ÉTICA DA USP.                                        #\n",
    "#  ENTENDO QUE LISTAS SEM ASSINATURA NÃO SERÃO CORRIGIDAS E,                   #\n",
    "#  AINDA ASSIM, PODERÃO SER PUNIDOS POR DESONESTIDADE ACADÊMICA.               #\n",
    "#                                                                              #\n",
    "#  Nome : Érico Tiago Meireles                                                 #\n",
    "#  NUSP : 9312428                                                              #\n",
    "#  Turma: MAC5768 Visão e Processamento de Imagens                             #\n",
    "#  Prof.: Ronaldo Fumio Hashimoto                                              #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EP3 - Segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importa os metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(rf\"../metadados.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação da tabela sumária geral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Lista todas as imagens dos dados do EP2\n",
    "\n",
    "path_list = []\n",
    "names = []\n",
    "path_folder = []\n",
    "for path, subdirs, files in os.walk(\"../data_EP2/\"):\n",
    "    for name in files:\n",
    "        path_list.append((os.path.join(path, name)))\n",
    "        path_folder.append(path.split(rf'/')[-1])\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dataframe com todas as imagens, diretórios e pastas do Ep2\n",
    "df_images = pd.DataFrame({'path' : path_list,\n",
    "                          'img' : names,\n",
    "                          'folder' : path_folder\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uma nova coluna \"classe\" para agrupar todas as classes presentes em cada imagem\n",
    "\n",
    "metadata['classe'] = metadata['classe_1']\n",
    "metadata['n_objetos'] = 1\n",
    "\n",
    "for i in range(2, 6):\n",
    "    metadata['classe'] += ', ' + metadata.apply(lambda row: row['classe_' + str(i)] if pd.notnull(row['classe_' + str(i)]) else '', axis=1)\n",
    "    metadata['n_objetos'] += metadata.apply(lambda row: 1 if pd.notnull(row['classe_' + str(i)]) else 0, axis=1)\n",
    "\n",
    "\n",
    "# Remove ',' no final do string\n",
    "metadata['classe'] = metadata['classe'].str.rstrip(', ')\n",
    "\n",
    "metadata['classe'] = metadata['classe'].str.rstrip(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>classe_1</th>\n",
       "      <th>classe_2</th>\n",
       "      <th>classe_3</th>\n",
       "      <th>classe_4</th>\n",
       "      <th>classe_5</th>\n",
       "      <th>fundo</th>\n",
       "      <th>iluminacao</th>\n",
       "      <th>classe</th>\n",
       "      <th>n_objetos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.JPEG</td>\n",
       "      <td>garfo</td>\n",
       "      <td>pilha</td>\n",
       "      <td>faca</td>\n",
       "      <td>colher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sofa</td>\n",
       "      <td>interno-claro</td>\n",
       "      <td>garfo, pilha, faca, colher</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.JPEG</td>\n",
       "      <td>som</td>\n",
       "      <td>livro</td>\n",
       "      <td>capacete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sofa</td>\n",
       "      <td>interno-claro</td>\n",
       "      <td>som, livro, capacete</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        img classe_1 classe_2  classe_3 classe_4 classe_5 fundo  \\\n",
       "0  001.JPEG    garfo    pilha      faca   colher      NaN  sofa   \n",
       "1  002.JPEG      som    livro  capacete      NaN      NaN  sofa   \n",
       "\n",
       "      iluminacao                      classe  n_objetos  \n",
       "0  interno-claro  garfo, pilha, faca, colher          4  \n",
       "1  interno-claro        som, livro, capacete          3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as palavras por vírgula e cria uma lista única de palavras\n",
    "palavras_unicas = set(palavra.strip() for palavra in ','.join(metadata['classe']).split(',') if palavra)\n",
    "# Converte o conjunto de volta para uma lista\n",
    "lista_palavras_unicas = list(palavras_unicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TABELA SUMÁRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define type como o tipo de transformação utilizada\n",
    "df_images['type'] = df_images['path'].str.split(rf'\\\\').str[-2]\n",
    "df_images['type'] = df_images['type'].str.split(rf'/').str[-1]\n",
    "# Garantindo que o nome tenha JPEG maiúsculo\n",
    "df_images['img'] = df_images['img'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a relação de todas as imagens com a sua classe e iluminação, através do metadado:\n",
    "\n",
    "metadata = df_images.merge(metadata, on='img', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_unique = metadata.drop_duplicates('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação da Tabela Detalhada por Classe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# Lista para armazenar dados para o CSV\n",
    "\n",
    "dados_csv = []\n",
    "\n",
    "# Função para suavizar a imagem\n",
    "def apply_smoothing(img, method='gaussian'):\n",
    "    if method == 'gaussian':\n",
    "        return cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    elif method == 'median':\n",
    "        return cv2.medianBlur(img, 5)\n",
    "    elif method == 'bilateral':\n",
    "        return cv2.bilateralFilter(img, 9, 75, 75)\n",
    "    else:\n",
    "        raise ValueError('Unknown smoothing method.')\n",
    "\n",
    "# Função para detecção de bordas gaussian, median, bilateral, gradient, canny, 'marr_hildreth'\n",
    "def edge_detection(img, method='canny'):\n",
    "    if method == 'gradient':\n",
    "        grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        grad_mag = np.uint8(grad_mag / np.max(grad_mag) * 255)\n",
    "        _, binary_img = cv2.threshold(grad_mag, 100, 255, cv2.THRESH_BINARY)\n",
    "        return binary_img\n",
    "    elif method == 'canny':\n",
    "        return cv2.Canny(img, 50, 150)\n",
    "    elif method == 'marr_hildreth':\n",
    "        blurred = cv2.GaussianBlur(img, (0, 0), 1.0)\n",
    "        log = cv2.Laplacian(blurred, cv2.CV_64F)\n",
    "        log = np.uint8((log - log.min()) / (log.max() - log.min()) * 255)\n",
    "        _, binary_img = cv2.threshold(log, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        return binary_img\n",
    "    else:\n",
    "        raise ValueError('Unknown edge detection method.')\n",
    "\n",
    "# Função para traçar os contornos\n",
    "def draw_contours(img, contours):\n",
    "    img_contours = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(img_contours, contours, -1, (255, 0, 255), 1)\n",
    "    return img_contours\n",
    "\n",
    "# Função para filtrar contornos próximos das bordas\n",
    "def filter_contours_near_edges(contours, img_shape, margin=10):\n",
    "    height, width = img_shape\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if x > margin and y > margin and (x + w) < (width - margin) and (y + h) < (height - margin):\n",
    "            filtered_contours.append(contour)\n",
    "    return filtered_contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calcular os valores das áreas dos objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['021.JPEG', '052.JPEG']\n",
      "021.JPEG\n",
      "..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\n",
      "021.JPEG\n",
      "[68900.5, 66508.5, 1102.5, 199.5, 133.0, 119.5, 104.0, 73.0, 68.5, 52.5, 52.0, 50.0, 48.5, 44.0, 40.5, 39.5, 39.5, 39.0, 36.5, 36.0, 36.0, 35.0, 33.5, 30.5, 26.5, 26.5, 25.5, 24.5, 24.0, 23.0, 22.0, 21.5, 21.0, 20.5, 16.5, 16.0, 16.0, 15.5, 15.0, 15.0, 14.0, 13.0, 12.5, 11.5, 10.0, 9.5, 9.5, 9.5, 9.5, 8.5, 8.5, 8.0, 8.0, 7.5, 7.5, 7.5, 7.5, 7.0, 7.0, 7.0, 6.5, 5.5, 5.5, 5.5, 5.5, 5.5, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.5]\n",
      "4\n",
      "052.JPEG\n",
      "..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\n",
      "052.JPEG\n",
      "[684.5, 329.0, 148.5, 88.5, 76.5, 68.0, 68.0, 57.0, 18.5, 17.5, 15.0, 14.5, 14.5, 14.0, 13.5, 12.5, 12.5, 11.5, 11.5, 9.5, 9.5, 8.5, 7.0, 7.0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Função principal para processar as imagens\n",
    "def process_images(input_dir, smoothing_method='gaussian', edge_method='canny'):\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        print(files)\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            print(root)\n",
    "\n",
    "            # if file in file.endswith('.jpeg') or file.endswith('.JPEG'):\n",
    "            #file.endswith('.jpeg') or file.endswith('.JPEG'):\n",
    "            img_path = os.path.join(root, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "            if img is not None:\n",
    "                print(file.upper())\n",
    "\n",
    "                # Aplicar a suavização\n",
    "                img_smoothed = apply_smoothing(img, smoothing_method)\n",
    "                n = int(metadata_unique.loc[metadata_unique['img'] == file.upper()]['n_objetos'].item()) #\n",
    "                    \n",
    "                    \n",
    "                # Aplicar a detecção de bordas\n",
    "                img_edges = edge_detection(img_smoothed, edge_method)\n",
    "\n",
    "                # Encontrar contornos\n",
    "                contours, hierarchy = cv2.findContours(img_edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # Filtrar contornos próximos das bordas\n",
    "                contours = filter_contours_near_edges(contours, img.shape)\n",
    "\n",
    "                label_img = label(img_smoothed, connectivity=2)\n",
    "                props = regionprops(label_img)\n",
    "\n",
    "                # Calcular a área dos contornos\n",
    "                areas = []\n",
    "                for c in contours:\n",
    "                    areas.append(cv2.contourArea(c))\n",
    "\n",
    "\n",
    "                areas_sorted = sorted(areas, reverse=True)\n",
    "\n",
    "                major_contours = []\n",
    "                print (areas_sorted)\n",
    "                print(n)\n",
    "\n",
    "                try:\n",
    "\n",
    "                    for c in contours:\n",
    "                        if len(areas_sorted) >= n:\n",
    "                            if (cv2.contourArea(c)) > float(areas_sorted[n]):\n",
    "                                major_contours.append(c)\n",
    "                        else:\n",
    "                            if (cv2.contourArea(c)) > len(areas_sorted):\n",
    "                                major_contours.append(c)\n",
    "                    img_contours = draw_contours(img, major_contours)\n",
    "                    # Desenhar os contornos maiores na imagem original\n",
    "    \n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                        # # Filtrar props com base nas áreas dos maiores contornos\n",
    "                props_filtradas = [prop for prop in props if prop.area in areas]\n",
    "                props_img = props_filtradas\n",
    "\n",
    "                # Ordenar as áreas do maior para o menor valor\n",
    "                object_sorted = sorted(zip(areas, props_img), key=lambda x: x[0], reverse=True)\n",
    "                \n",
    "                \n",
    "                # Traçar apenas os contornos das maiores áreas\n",
    "                #n = len(areas_sorted) // 2  # Por exemplo, usar metade das áreas maiores\n",
    "                # Para cada uma das três maiores áreas, recuperar diâmetro e menor eixo\n",
    "\n",
    "                maiores_areas_props = areas_sorted[:n]\n",
    "                maiores_obj_props = object_sorted[:n]\n",
    "\n",
    "\n",
    "                for idx, (area, prop) in enumerate(maiores_obj_props):\n",
    "                    if area is not None and prop is not None:\n",
    "                        try:\n",
    "                            diameter = prop.major_axis_length  # Supondo que você queira o diâmetro\n",
    "                            minor_axis = prop.minor_axis_length  # Supondo que você queira o menor eixo\n",
    "                            centroid = prop.centroid  # Obter o centroide do contorno\n",
    "                            centroid_x, centroid_y = centroid[1], centroid[0]  # Coordenadas x e y do centroide\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Erro ao calcular propriedades: {e}\")\n",
    "                            diameter = None\n",
    "                            minor_axis = None           \n",
    "                            centroid_x = None\n",
    "                            centroid_y = None\n",
    "                    else:\n",
    "                        area = ''\n",
    "                        diameter = ''\n",
    "                        minor_axis = ''\n",
    "                        centroid_x = ''\n",
    "                        centroid_y = ''\n",
    "                \n",
    "                    # Adicionar os dados para o CSV\n",
    "                    dados_csv.append({\n",
    "                        'img': file,  # Preencha conforme necessário  # Preencha conforme necessário\n",
    "                        'path_origin': img_path,\n",
    "                        'Objeto': '',  # Preencha conforme necessário\n",
    "                        'Classe': '',  # Preencha conforme necessário\n",
    "                        'n_contorno': idx,\n",
    "                        'Área': f'{area:.10f}',\n",
    "                        'Diâmetro': f'{diameter:.15f}',\n",
    "                        'Minor': f'{minor_axis:.15f}',\n",
    "                        'Centroide_X': f'{centroid_x:.4f}',\n",
    "                        'Centroide_Y': f'{centroid_y:.4f}'\n",
    "                    })\n",
    "\n",
    "                        # # Imprimir os dados\n",
    "                        # print(f\"Imagem: {imagem_path} - Área: {area}, Diâmetro: {diameter}, Menor: {minor_axis}\")\n",
    "    \n",
    "\n",
    "\n",
    "                    # major_contours = [c for c in maiores_areas_props if c and c is not None]\n",
    "                    # print(major_contours)\n",
    "\n",
    "\n",
    "                    # except:\n",
    "                    #     major_contours = [c for c in maiores_areas_props]\n",
    "                    # Desenhar os contornos maiores\n",
    "    return dados_csv\n",
    "\n",
    "\n",
    "# Caminhos para os diretórios das imagens suavizadas\n",
    "# caminho_suavizado_augmented = os.path.join('augmentedDataset')\n",
    "# caminho_suavizado_normalized = os.path.join('normalizedDataset')\n",
    "# output_dir_augmented = os.path.join('augmentedDataset_segmented')\n",
    "# output_dir_normalized = os.path.join('normalizedDataset_segmented')\n",
    "\n",
    "\n",
    "caminho_selected_imgs_original = rf'..\\data_EP3\\selectedData\\origin'\n",
    "\n",
    "\n",
    "# # Processar e segmentar as imagens nos datasets suavizados\n",
    "# process_images(caminho_suavizado_augmented, output_dir_augmented, 'gaussian', 'canny')\n",
    "# process_images(caminho_suavizado_normalized, output_dir_normalized, 'gaussian', 'canny')\n",
    "\n",
    "\n",
    "data_characteristics = process_images(caminho_selected_imgs_original, 'gaussian', 'canny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characteristics = pd.DataFrame(data_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>path_origin</th>\n",
       "      <th>Objeto</th>\n",
       "      <th>Classe</th>\n",
       "      <th>n_contorno</th>\n",
       "      <th>Área</th>\n",
       "      <th>Diâmetro</th>\n",
       "      <th>Minor</th>\n",
       "      <th>Centroide_X</th>\n",
       "      <th>Centroide_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>021.JPEG</td>\n",
       "      <td>..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>68900.5000000000</td>\n",
       "      <td>4.318667337728677</td>\n",
       "      <td>3.679464844031199</td>\n",
       "      <td>287.6154</td>\n",
       "      <td>6.6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>021.JPEG</td>\n",
       "      <td>..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>66508.5000000000</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>447.5000</td>\n",
       "      <td>5.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>021.JPEG</td>\n",
       "      <td>..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1102.5000000000</td>\n",
       "      <td>19.489045764668695</td>\n",
       "      <td>2.814604741456738</td>\n",
       "      <td>487.4615</td>\n",
       "      <td>22.4103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>021.JPEG</td>\n",
       "      <td>..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>199.5000000000</td>\n",
       "      <td>8.000000000000000</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>511.5000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>052.JPEG</td>\n",
       "      <td>..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\052.JPEG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>684.5000000000</td>\n",
       "      <td>13.091133555875818</td>\n",
       "      <td>2.065591117977291</td>\n",
       "      <td>750.6667</td>\n",
       "      <td>4.3333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        img  \\\n",
       "0  021.JPEG   \n",
       "1  021.JPEG   \n",
       "2  021.JPEG   \n",
       "3  021.JPEG   \n",
       "4  052.JPEG   \n",
       "\n",
       "                                                            path_origin  \\\n",
       "0  ..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG   \n",
       "1  ..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG   \n",
       "2  ..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG   \n",
       "3  ..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\021.JPEG   \n",
       "4  ..\\data_EP3\\selectedData\\origin\\augmentedDataset\\laplaciano\\052.JPEG   \n",
       "\n",
       "  Objeto Classe  n_contorno              Área            Diâmetro  \\\n",
       "0                         0  68900.5000000000   4.318667337728677   \n",
       "1                         1  66508.5000000000   2.000000000000000   \n",
       "2                         2   1102.5000000000  19.489045764668695   \n",
       "3                         3    199.5000000000   8.000000000000000   \n",
       "4                         0    684.5000000000  13.091133555875818   \n",
       "\n",
       "               Minor Centroide_X Centroide_Y  \n",
       "0  3.679464844031199    287.6154      6.6154  \n",
       "1  2.000000000000000    447.5000      5.5000  \n",
       "2  2.814604741456738    487.4615     22.4103  \n",
       "3  2.000000000000000    511.5000      3.0000  \n",
       "4  2.065591117977291    750.6667      4.3333  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_characteristics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characteristics.to_csv('..\\image_characteristics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
